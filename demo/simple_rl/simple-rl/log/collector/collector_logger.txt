[2022-03-22 17:20:38,911][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 448
envstep_count: 47750
train_sample_count: 47750
avg_envstep_per_episode: 106.58482142857143
avg_sample_per_episode: 106.58482142857143
avg_envstep_per_sec: 29.271928057127067
avg_train_sample_per_sec: 29.271928057127067
avg_episode_per_sec: 0.274635052766344
collect_time: 1631.2557173142523
reward_mean: -24.751088921129078
reward_std: 400.3960032999391
reward_max: 116.01712692950586
reward_min: -7060.021158292678
total_envstep_count: 47750
total_train_sample_count: 47750
total_episode_count: 448
total_duration: 1631.2557173142523
[2022-03-22 17:37:27,130][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 191
envstep_count: 33710
train_sample_count: 33710
avg_envstep_per_episode: 176.49214659685865
avg_sample_per_episode: 176.49214659685865
avg_envstep_per_sec: 35.61079479221322
avg_train_sample_per_sec: 35.61079479221322
avg_episode_per_sec: 0.20176985480014017
collect_time: 946.6230730511846
reward_mean: 82.50469297230846
reward_std: 157.84570866000274
reward_max: 639.5863498485639
reward_min: -2018.2438879293209
total_envstep_count: 81460
total_train_sample_count: 81460
total_episode_count: 639
total_duration: 2577.878790365437
[2022-03-22 17:51:53,374][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 144
envstep_count: 34740
train_sample_count: 34740
avg_envstep_per_episode: 241.25
avg_sample_per_episode: 241.25
avg_envstep_per_sec: 41.97873837965542
avg_train_sample_per_sec: 41.97873837965542
avg_episode_per_sec: 0.1740051331799188
collect_time: 827.5617929679469
reward_mean: 153.7575305197942
reward_std: 178.0279123624864
reward_max: 753.9499585134012
reward_min: 63.974611026380416
total_envstep_count: 116200
total_train_sample_count: 116200
total_episode_count: 783
total_duration: 3405.440583333384
[2022-03-22 18:06:12,376][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 110
envstep_count: 38017
train_sample_count: 38017
avg_envstep_per_episode: 345.6090909090909
avg_sample_per_episode: 345.6090909090909
avg_envstep_per_sec: 50.07373761806419
avg_train_sample_per_sec: 50.07373761806419
avg_episode_per_sec: 0.14488547591832762
collect_time: 759.2203380137795
reward_mean: 260.97685345710147
reward_std: 249.93984630181092
reward_max: 736.330183324801
reward_min: 82.88301995863962
total_envstep_count: 154217
total_train_sample_count: 154217
total_episode_count: 893
total_duration: 4164.660921347164
[2022-03-22 18:18:38,751][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 91
envstep_count: 36925
train_sample_count: 36925
avg_envstep_per_episode: 405.7692307692308
avg_sample_per_episode: 405.7692307692308
avg_envstep_per_sec: 52.07293970301217
avg_train_sample_per_sec: 52.07293970301217
avg_episode_per_sec: 0.12833141538183093
collect_time: 709.1015066672733
reward_mean: 302.84737569040595
reward_std: 244.53324877018852
reward_max: 815.3503164078742
reward_min: 15.317848877599777
total_envstep_count: 191142
total_train_sample_count: 191142
total_episode_count: 984
total_duration: 4873.762428014437
[2022-03-22 18:30:54,989][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 82
envstep_count: 36400
train_sample_count: 36400
avg_envstep_per_episode: 443.9024390243902
avg_sample_per_episode: 443.9024390243902
avg_envstep_per_sec: 53.83633707555212
avg_train_sample_per_sec: 53.83633707555212
avg_episode_per_sec: 0.12127966044492512
collect_time: 676.1232650155498
reward_mean: 281.6613071411173
reward_std: 422.93190138057264
reward_max: 1217.2847475254898
reward_min: -1985.8687330330115
total_envstep_count: 227542
total_train_sample_count: 227542
total_episode_count: 1066
total_duration: 5549.885693029987
[2022-03-22 18:43:16,835][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 82
envstep_count: 38415
train_sample_count: 38415
avg_envstep_per_episode: 468.4756097560976
avg_sample_per_episode: 468.4756097560976
avg_envstep_per_sec: 54.61623865004546
avg_train_sample_per_sec: 54.61623865004546
avg_episode_per_sec: 0.11658288609407075
collect_time: 703.362240782358
reward_mean: 365.6454011330144
reward_std: 308.02901602514675
reward_max: 876.6495873569119
reward_min: 92.12824723919326
total_envstep_count: 265957
total_train_sample_count: 265957
total_episode_count: 1148
total_duration: 6253.247933812345
[2022-03-22 18:55:21,426][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 53
envstep_count: 38037
train_sample_count: 38037
avg_envstep_per_episode: 717.6792452830189
avg_sample_per_episode: 717.6792452830189
avg_envstep_per_sec: 60.287435665954675
avg_train_sample_per_sec: 60.287435665954675
avg_episode_per_sec: 0.08400331493797086
collect_time: 630.9274823158572
reward_mean: 586.8349020736421
reward_std: 269.0133471186171
reward_max: 846.035796902077
reward_min: 39.78695419324494
total_envstep_count: 303994
total_train_sample_count: 303994
total_episode_count: 1201
total_duration: 6884.175416128202
[2022-03-22 19:06:47,941][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 70
envstep_count: 36328
train_sample_count: 36328
avg_envstep_per_episode: 518.9714285714285
avg_sample_per_episode: 518.9714285714285
avg_envstep_per_sec: 56.03591911423193
avg_train_sample_per_sec: 56.03591911423193
avg_episode_per_sec: 0.10797495975545682
collect_time: 648.2984588143119
reward_mean: 401.185941413126
reward_std: 364.24081612107284
reward_max: 1293.6197443044462
reward_min: -10.659920781357426
total_envstep_count: 340322
total_train_sample_count: 340322
total_episode_count: 1271
total_duration: 7532.473874942514
[2022-03-22 19:20:05,616][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 67
envstep_count: 37505
train_sample_count: 37505
avg_envstep_per_episode: 559.776119402985
avg_sample_per_episode: 559.776119402985
avg_envstep_per_sec: 54.467123998998446
avg_train_sample_per_sec: 54.467123998998446
avg_episode_per_sec: 0.09730162132870007
collect_time: 688.5805096059349
reward_mean: 329.15146176205064
reward_std: 669.9885579687206
reward_max: 1296.2495559386396
reward_min: -4380.377249686011
total_envstep_count: 377827
total_train_sample_count: 377827
total_episode_count: 1338
total_duration: 8221.05438454845
[2022-03-22 19:32:57,375][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 40
envstep_count: 41418
train_sample_count: 41418
avg_envstep_per_episode: 1035.45
avg_sample_per_episode: 1035.45
avg_envstep_per_sec: 56.54015952098063
avg_train_sample_per_sec: 56.54015952098063
avg_episode_per_sec: 0.05460443239266081
collect_time: 732.541265374938
reward_mean: 817.5982041064547
reward_std: 416.22046153228064
reward_max: 1897.1299727406517
reward_min: 15.229861901638802
total_envstep_count: 419245
total_train_sample_count: 419245
total_episode_count: 1378
total_duration: 8953.595649923387
[2022-03-22 19:47:19,201][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 30
envstep_count: 41384
train_sample_count: 41384
avg_envstep_per_episode: 1379.4666666666667
avg_sample_per_episode: 1379.4666666666667
avg_envstep_per_sec: 56.44844311180882
avg_train_sample_per_sec: 56.44844311180882
avg_episode_per_sec: 0.040920483601253256
collect_time: 733.1291656357943
reward_mean: 1171.805292827218
reward_std: 352.15264326580086
reward_max: 1815.078651656172
reward_min: 186.46165664152463
total_envstep_count: 460629
total_train_sample_count: 460629
total_episode_count: 1408
total_duration: 9686.72481555918
[2022-03-22 19:59:50,719][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 38
envstep_count: 39199
train_sample_count: 39199
avg_envstep_per_episode: 1031.5526315789473
avg_sample_per_episode: 1031.5526315789473
avg_envstep_per_sec: 55.055356485622156
avg_train_sample_per_sec: 55.055356485622156
avg_episode_per_sec: 0.053371349943969026
collect_time: 711.9924836057853
reward_mean: 903.2395354146465
reward_std: 474.7780398897723
reward_max: 1752.2790751518996
reward_min: 33.86665920371624
total_envstep_count: 499828
total_train_sample_count: 499828
total_episode_count: 1446
total_duration: 10398.717299164966
[2022-03-22 20:14:58,987][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 43
envstep_count: 42365
train_sample_count: 42365
avg_envstep_per_episode: 985.2325581395348
avg_sample_per_episode: 985.2325581395348
avg_envstep_per_sec: 55.10402342911699
avg_train_sample_per_sec: 55.10402342911699
avg_episode_per_sec: 0.05592996594953454
collect_time: 768.8186336247511
reward_mean: 769.8060783680901
reward_std: 616.4326439158187
reward_max: 1857.1542205625894
reward_min: 116.48026517862922
total_envstep_count: 542193
total_train_sample_count: 542193
total_episode_count: 1489
total_duration: 11167.535932789717
[2022-03-22 20:32:26,896][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 29
envstep_count: 42535
train_sample_count: 42535
avg_envstep_per_episode: 1466.7241379310344
avg_sample_per_episode: 1466.7241379310344
avg_envstep_per_sec: 42.344462446947816
avg_train_sample_per_sec: 42.344462446947816
avg_episode_per_sec: 0.028870093122404763
collect_time: 1004.4997041417377
reward_mean: 1070.647560427821
reward_std: 604.4837970835415
reward_max: 1819.8717302946238
reward_min: -1356.2107288140317
total_envstep_count: 584728
total_train_sample_count: 584728
total_episode_count: 1518
total_duration: 12172.035636931454
[2022-03-22 20:55:07,938][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 47
envstep_count: 43028
train_sample_count: 43028
avg_envstep_per_episode: 915.4893617021277
avg_sample_per_episode: 915.4893617021277
avg_envstep_per_sec: 35.703221340655325
avg_train_sample_per_sec: 35.703221340655325
avg_episode_per_sec: 0.038999056498345265
collect_time: 1205.157360717027
reward_mean: 775.9705858784397
reward_std: 668.9257299318924
reward_max: 1799.6891845956832
reward_min: 9.995777022452861
total_envstep_count: 627756
total_train_sample_count: 627756
total_episode_count: 1565
total_duration: 13377.19299764848
[2022-03-22 21:13:41,150][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 57
envstep_count: 40072
train_sample_count: 40072
avg_envstep_per_episode: 703.0175438596491
avg_sample_per_episode: 703.0175438596491
avg_envstep_per_sec: 37.47588200990062
avg_train_sample_per_sec: 37.47588200990062
avg_episode_per_sec: 0.05330717894201276
collect_time: 1069.27436662901
reward_mean: 598.2835948216153
reward_std: 629.4813394570624
reward_max: 1864.8676061932613
reward_min: 80.35295760380386
total_envstep_count: 667828
total_train_sample_count: 667828
total_episode_count: 1622
total_duration: 14446.46736427749
[2022-03-22 21:34:35,637][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 78
envstep_count: 39949
train_sample_count: 39949
avg_envstep_per_episode: 512.1666666666666
avg_sample_per_episode: 512.1666666666666
avg_envstep_per_sec: 35.459993605751066
avg_train_sample_per_sec: 35.459993605751066
avg_episode_per_sec: 0.06923526249089046
collect_time: 1126.59354776423
reward_mean: 417.58944824855536
reward_std: 530.4839302108162
reward_max: 1733.0840323573009
reward_min: 18.28226453350179
total_envstep_count: 707777
total_train_sample_count: 707777
total_episode_count: 1700
total_duration: 15573.060912041721
[2022-03-22 21:57:15,272][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 43
envstep_count: 41336
train_sample_count: 41336
avg_envstep_per_episode: 961.3023255813954
avg_sample_per_episode: 961.3023255813954
avg_envstep_per_sec: 31.440647825681406
avg_train_sample_per_sec: 31.440647825681406
avg_episode_per_sec: 0.03270630579892347
collect_time: 1314.7311794967486
reward_mean: 850.9173129158697
reward_std: 579.9940959952465
reward_max: 1758.407517669004
reward_min: 16.204810454437986
total_envstep_count: 749113
total_train_sample_count: 749113
total_episode_count: 1743
total_duration: 16887.79209153847
[2022-03-22 22:21:16,799][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 59
envstep_count: 37835
train_sample_count: 37835
avg_envstep_per_episode: 641.271186440678
avg_sample_per_episode: 641.271186440678
avg_envstep_per_sec: 28.705605606546953
avg_train_sample_per_sec: 28.705605606546953
avg_episode_per_sec: 0.04476359801205947
collect_time: 1318.0352478392194
reward_mean: 535.649103602589
reward_std: 615.420782048438
reward_max: 1816.213085872657
reward_min: 72.39016442714176
total_envstep_count: 786948
total_train_sample_count: 786948
total_episode_count: 1802
total_duration: 18205.82733937769
[2022-03-22 22:44:02,136][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 90
envstep_count: 36729
train_sample_count: 36729
avg_envstep_per_episode: 408.1
avg_sample_per_episode: 408.1
avg_envstep_per_sec: 27.80728060437669
avg_train_sample_per_sec: 27.80728060437669
avg_episode_per_sec: 0.06813839893255744
collect_time: 1320.8411323119128
reward_mean: 231.87976450573126
reward_std: 492.04754334337156
reward_max: 1664.3980820959437
reward_min: -2145.2444645085334
total_envstep_count: 823677
total_train_sample_count: 823677
total_episode_count: 1892
total_duration: 19526.668471689605
[2022-03-22 23:07:35,396][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 39
envstep_count: 40448
train_sample_count: 40448
avg_envstep_per_episode: 1037.128205128205
avg_sample_per_episode: 1037.128205128205
avg_envstep_per_sec: 31.395465908319476
avg_train_sample_per_sec: 31.395465908319476
avg_episode_per_sec: 0.030271538034623704
collect_time: 1288.3388995759956
reward_mean: 903.7599564247497
reward_std: 374.36342661125315
reward_max: 1767.9474697675191
reward_min: 87.86617331651252
total_envstep_count: 864125
total_train_sample_count: 864125
total_episode_count: 1931
total_duration: 20815.0073712656
[2022-03-22 23:28:04,637][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 45
envstep_count: 41883
train_sample_count: 41883
avg_envstep_per_episode: 930.7333333333333
avg_sample_per_episode: 930.7333333333333
avg_envstep_per_sec: 35.23757582550996
avg_train_sample_per_sec: 35.23757582550996
avg_episode_per_sec: 0.03786001270558336
collect_time: 1188.589141528832
reward_mean: 805.2946438614894
reward_std: 487.4780033065589
reward_max: 1791.1992952789835
reward_min: 95.54258003009967
total_envstep_count: 906008
total_train_sample_count: 906008
total_episode_count: 1976
total_duration: 22003.596512794433
[2022-03-22 23:49:17,448][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 48
envstep_count: 37603
train_sample_count: 37603
avg_envstep_per_episode: 783.3958333333334
avg_sample_per_episode: 783.3958333333334
avg_envstep_per_sec: 34.156311816446106
avg_train_sample_per_sec: 34.156311816446106
avg_episode_per_sec: 0.04360032356964639
collect_time: 1100.9092609903605
reward_mean: 691.1965524586881
reward_std: 607.3280322265184
reward_max: 1845.7069292721899
reward_min: 77.87499332446808
total_envstep_count: 943611
total_train_sample_count: 943611
total_episode_count: 2024
total_duration: 23104.505773784793
[2022-03-23 00:11:49,392][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 45
envstep_count: 37255
train_sample_count: 37255
avg_envstep_per_episode: 827.8888888888889
avg_sample_per_episode: 827.8888888888889
avg_envstep_per_sec: 28.51524684588538
avg_train_sample_per_sec: 28.51524684588538
avg_episode_per_sec: 0.03444332594456696
collect_time: 1306.4940381315944
reward_mean: 637.4020928351433
reward_std: 600.6236460416316
reward_max: 1680.9234500219482
reward_min: -1732.9898726887177
total_envstep_count: 980866
total_train_sample_count: 980866
total_episode_count: 2069
total_duration: 24410.999811916387
[2022-03-23 00:35:44,964][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 29
envstep_count: 38849
train_sample_count: 38849
avg_envstep_per_episode: 1339.6206896551723
avg_sample_per_episode: 1339.6206896551723
avg_envstep_per_sec: 29.979515832062912
avg_train_sample_per_sec: 29.979515832062912
avg_episode_per_sec: 0.022379107805344398
collect_time: 1295.8514813121574
reward_mean: 1241.5133734420208
reward_std: 446.5022793749447
reward_max: 1771.8710536387662
reward_min: 97.87464562862556
total_envstep_count: 1019715
total_train_sample_count: 1019715
total_episode_count: 2098
total_duration: 25706.851293228545
[2022-03-23 01:01:19,813][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 39
envstep_count: 40934
train_sample_count: 40934
avg_envstep_per_episode: 1049.5897435897436
avg_sample_per_episode: 1049.5897435897436
avg_envstep_per_sec: 27.471993401005168
avg_train_sample_per_sec: 27.471993401005168
avg_episode_per_sec: 0.02617402996626769
collect_time: 1490.0265664195404
reward_mean: 784.6096612071877
reward_std: 748.1131756006432
reward_max: 1881.5776780749288
reward_min: -2043.7804935373442
total_envstep_count: 1060649
total_train_sample_count: 1060649
total_episode_count: 2137
total_duration: 27196.877859648084
[2022-03-23 01:24:20,847][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 75
envstep_count: 36385
train_sample_count: 36385
avg_envstep_per_episode: 485.1333333333333
avg_sample_per_episode: 485.1333333333333
avg_envstep_per_sec: 27.66893404560159
avg_train_sample_per_sec: 27.66893404560159
avg_episode_per_sec: 0.057033669188405085
collect_time: 1315.012712091956
reward_mean: 423.8658562495372
reward_std: 551.8287078451029
reward_max: 1739.797380692244
reward_min: -0.8806393257192138
total_envstep_count: 1097034
total_train_sample_count: 1097034
total_episode_count: 2212
total_duration: 28511.89057174004
[2022-03-23 01:49:06,189][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 101
envstep_count: 39224
train_sample_count: 39224
avg_envstep_per_episode: 388.35643564356434
avg_sample_per_episode: 388.35643564356434
avg_envstep_per_sec: 27.232987158279695
avg_train_sample_per_sec: 27.232987158279695
avg_episode_per_sec: 0.07012369220340223
collect_time: 1440.3120660993907
reward_mean: 303.71708133239554
reward_std: 465.81651428003016
reward_max: 1662.5059765713172
reward_min: 0.10245815580374451
total_envstep_count: 1136258
total_train_sample_count: 1136258
total_episode_count: 2313
total_duration: 29952.202637839433
[2022-03-23 02:13:08,012][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 42
envstep_count: 38403
train_sample_count: 38403
avg_envstep_per_episode: 914.3571428571429
avg_sample_per_episode: 914.3571428571429
avg_envstep_per_sec: 29.058962220722826
avg_train_sample_per_sec: 29.058962220722826
avg_episode_per_sec: 0.031780757057270494
collect_time: 1321.5544212591892
reward_mean: 807.5366933359791
reward_std: 386.6865254244502
reward_max: 1671.4059340276253
reward_min: 197.18308834759733
total_envstep_count: 1174661
total_train_sample_count: 1174661
total_episode_count: 2355
total_duration: 31273.75705909862
[2022-03-23 02:40:50,135][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 38
envstep_count: 42205
train_sample_count: 42205
avg_envstep_per_episode: 1110.657894736842
avg_sample_per_episode: 1110.657894736842
avg_envstep_per_sec: 26.097157234655135
avg_train_sample_per_sec: 26.097157234655135
avg_episode_per_sec: 0.02349702582435482
collect_time: 1617.2259537891282
reward_mean: 853.8969485948097
reward_std: 641.7991348094379
reward_max: 1764.8608213858295
reward_min: -1559.6546547330659
total_envstep_count: 1216866
total_train_sample_count: 1216866
total_episode_count: 2393
total_duration: 32890.98301288775
[2022-03-23 03:07:52,496][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 35
envstep_count: 41189
train_sample_count: 41189
avg_envstep_per_episode: 1176.8285714285714
avg_sample_per_episode: 1176.8285714285714
avg_envstep_per_sec: 27.392938527888134
avg_train_sample_per_sec: 27.392938527888134
avg_episode_per_sec: 0.023276914916023322
collect_time: 1503.6356891052928
reward_mean: 1104.932366876177
reward_std: 417.95988302030537
reward_max: 1767.8507945912795
reward_min: 108.90178827955161
total_envstep_count: 1258055
total_train_sample_count: 1258055
total_episode_count: 2428
total_duration: 34394.618701993044
[2022-03-23 03:32:33,033][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 37
envstep_count: 39616
train_sample_count: 39616
avg_envstep_per_episode: 1070.7027027027027
avg_sample_per_episode: 1070.7027027027027
avg_envstep_per_sec: 27.606631654115766
avg_train_sample_per_sec: 27.606631654115766
avg_episode_per_sec: 0.025783657391010788
collect_time: 1435.0175166731651
reward_mean: 975.2117963367965
reward_std: 583.709324051055
reward_max: 1727.4612904044916
reward_min: 80.81285946708651
total_envstep_count: 1297671
total_train_sample_count: 1297671
total_episode_count: 2465
total_duration: 35829.63621866621
[2022-03-23 03:56:05,333][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 75
envstep_count: 37467
train_sample_count: 37467
avg_envstep_per_episode: 499.56
avg_sample_per_episode: 499.56
avg_envstep_per_sec: 27.98134844179441
avg_train_sample_per_sec: 27.98134844179441
avg_episode_per_sec: 0.05601198743252945
collect_time: 1338.9990864070483
reward_mean: 203.21216725913928
reward_std: 928.4629513067831
reward_max: 1715.1345996187174
reward_min: -6485.792640785109
total_envstep_count: 1335138
total_train_sample_count: 1335138
total_episode_count: 2540
total_duration: 37168.63530507326
[2022-03-23 04:20:09,435][sample_serial_collector.py][line: 331][    INFO] collect end:
episode_count: 41
envstep_count: 41185
train_sample_count: 41185
avg_envstep_per_episode: 1004.5121951219512
avg_sample_per_episode: 1004.5121951219512
avg_envstep_per_sec: 29.438932762111516
avg_train_sample_per_sec: 29.438932762111516
avg_episode_per_sec: 0.029306695234832394
collect_time: 1398.9977263376172
reward_mean: 898.5069682048652
reward_std: 685.5476162470359
reward_max: 1825.0683399242826
reward_min: 77.80180713472679
total_envstep_count: 1376323
total_train_sample_count: 1376323
total_episode_count: 2581
total_duration: 38567.63303141088
